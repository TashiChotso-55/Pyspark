{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e1f7c9",
   "metadata": {},
   "source": [
    "# Telecom Churn\n",
    "- Team 1\n",
    "- Team members\n",
    "            Tashi Chotso - 20BDA01\n",
    "            Jerry Raju Mathew - 20BDA16\n",
    "            Gunam Ramya Sri - 20BDA33\n",
    "            PrajjWal Patel - 20BDA48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df21efb",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "- In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition or reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    "1. Extract, load, and read the data as text files as RDD Transform    \n",
    "2. Transform: Exploratory data analysis using rdd\n",
    "\n",
    "    - A. Replace Contract column values\n",
    "        - Month-to-month -1m\n",
    "        - One Year - 1y\n",
    "        - Two Year - 2y\n",
    "        - rest all - Others\n",
    "        \n",
    "    - B. Unique customer count\n",
    "\n",
    "    - C. Describe the categorical and numerical columns seperately\n",
    "\n",
    "    - D. GroupBy contract and avg of totalcharges\n",
    "\n",
    "    - E. Using accumulator add the totalcharges                         \n",
    "    \n",
    "         \n",
    "3. Load: Save analysis report\n",
    "\n",
    "    - GroupBy contract and avg of totalcharges save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe8f344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "from random import random\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from pyspark.mllib.stat import Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb87fc4",
   "metadata": {},
   "source": [
    "The first thing a Spark program must do is to create a SparkContext object, which tells Spark how to access a cluster. To create a SparkContext you first need to build a SparkConf object that contains information about your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc58957",
   "metadata": {},
   "source": [
    "## 1. Extract, load, and read the data as text files as RDD Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c74d888b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").\\\n",
    "        appName(\"SparkApplication\").\\\n",
    "        config(\"spark.driver.bindAddress\",\"localhost\").\\\n",
    "        config(\"spark.ui.port\",\"4041\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e28d4054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://tashis-air:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkApplication</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff695a3ab50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4ea03",
   "metadata": {},
   "source": [
    "### To read CSV  in Spark into single RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "283ea390",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ec018c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.read csv file in rdd\n",
    "data=sc.textFile(\"telecomChurn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24ec09ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " telecomChurn.csv MapPartitionsRDD[287] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print('\\n',data) #what file rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21e8f7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print('\\n',type(data)) # variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7069dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['__add__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_computeFractionForSampleSize', '_defaultReducePartitions', '_id', '_is_barrier', '_jrdd', '_jrdd_deserializer', '_memory_limit', '_pickled', '_reserialize', '_to_java_object_rdd', 'aggregate', 'aggregateByKey', 'barrier', 'cache', 'cartesian', 'checkpoint', 'coalesce', 'cogroup', 'collect', 'collectAsMap', 'collectWithJobGroup', 'combineByKey', 'context', 'count', 'countApprox', 'countApproxDistinct', 'countByKey', 'countByValue', 'ctx', 'distinct', 'filter', 'first', 'flatMap', 'flatMapValues', 'fold', 'foldByKey', 'foreach', 'foreachPartition', 'fullOuterJoin', 'getCheckpointFile', 'getNumPartitions', 'getResourceProfile', 'getStorageLevel', 'glom', 'groupBy', 'groupByKey', 'groupWith', 'has_resource_profile', 'histogram', 'id', 'intersection', 'isCheckpointed', 'isEmpty', 'isLocallyCheckpointed', 'is_cached', 'is_checkpointed', 'join', 'keyBy', 'keys', 'leftOuterJoin', 'localCheckpoint', 'lookup', 'map', 'mapPartitions', 'mapPartitionsWithIndex', 'mapPartitionsWithSplit', 'mapValues', 'max', 'mean', 'meanApprox', 'min', 'name', 'partitionBy', 'partitioner', 'persist', 'pipe', 'randomSplit', 'reduce', 'reduceByKey', 'reduceByKeyLocally', 'repartition', 'repartitionAndSortWithinPartitions', 'rightOuterJoin', 'sample', 'sampleByKey', 'sampleStdev', 'sampleVariance', 'saveAsHadoopDataset', 'saveAsHadoopFile', 'saveAsNewAPIHadoopDataset', 'saveAsNewAPIHadoopFile', 'saveAsPickleFile', 'saveAsSequenceFile', 'saveAsTextFile', 'setName', 'sortBy', 'sortByKey', 'stats', 'stdev', 'subtract', 'subtractByKey', 'sum', 'sumApprox', 'take', 'takeOrdered', 'takeSample', 'toDF', 'toDebugString', 'toLocalIterator', 'top', 'treeAggregate', 'treeReduce', 'union', 'unpersist', 'values', 'variance', 'withResources', 'zip', 'zipWithIndex', 'zipWithUniqueId']\n"
     ]
    }
   ],
   "source": [
    "print('\\n',dir(data))# what attributes are avaiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5ef0e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID,gender,SeniorCitizen,Partner,Dependents,tenure,PhoneService,MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,StreamingTV,StreamingMovies,Contract,PaperlessBilling,PaymentMethod,MonthlyCharges,TotalCharges,Churn\n"
     ]
    }
   ],
   "source": [
    "#header\n",
    "header=data.first()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af1c0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove header\n",
    "rdd1= data.filter(lambda line: line !=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83bdcc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " file has: 7043 row\n"
     ]
    }
   ],
   "source": [
    "#total record counts\n",
    "print('\\n file has:',rdd1.count(),'row') #counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "736ca602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " file line: 7590-VHVEG,Female,0,Yes,No,1,No,No phone service,DSL,No,Yes,No,No,No,No,Month-to-month,Yes,Electronic check,29.85,29.85,No\n"
     ]
    }
   ],
   "source": [
    "#filter first row\n",
    "print('\\n file line:',rdd1.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88464fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7590-VHVEG,Female,0,Yes,No,1,No,No phone service,DSL,No,Yes,No,No,No,No,Month-to-month,Yes,Electronic check,29.85,29.85,No',\n",
       " '5575-GNVDE,Male,0,No,No,34,Yes,No,DSL,Yes,No,Yes,No,No,No,One year,No,Mailed check,56.95,1889.5,No',\n",
       " '3668-QPYBK,Male,0,No,No,2,Yes,No,DSL,Yes,Yes,No,No,No,No,Month-to-month,Yes,Mailed check,53.85,108.15,Yes',\n",
       " '7795-CFOCW,Male,0,No,No,45,No,No phone service,DSL,Yes,No,Yes,Yes,No,No,One year,No,Bank transfer (automatic),42.3,1840.75,No',\n",
       " '9237-HQITU,Female,0,No,No,2,Yes,No,Fiber optic,No,No,No,No,No,No,Month-to-month,Yes,Electronic check,70.7,151.65,Yes']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.take(5) #take file element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e112448b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total unique records count\n",
    "rdd1.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "289a0834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial partition count:1\n"
     ]
    }
   ],
   "source": [
    "print(\"initial partition count:\"+str(rdd1.getNumPartitions()))\n",
    "#Outputs: initial partition count:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f87108a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1= rdd1.map(lambda line: line.split(\",\")) # split by ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a97c7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7590-VHVEG',\n",
       "  'Female',\n",
       "  '0',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  '1',\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'Month-to-month',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  '29.85',\n",
       "  '29.85',\n",
       "  'No'],\n",
       " ['5575-GNVDE',\n",
       "  'Male',\n",
       "  '0',\n",
       "  'No',\n",
       "  'No',\n",
       "  '34',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'DSL',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'One year',\n",
       "  'No',\n",
       "  'Mailed check',\n",
       "  '56.95',\n",
       "  '1889.5',\n",
       "  'No']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e5736",
   "metadata": {},
   "source": [
    "## 2. Transform: Exploratory data analysis using rdd\n",
    "\n",
    "##   A. Replace Contract column values\n",
    "\n",
    "    - Month-to-month -1m\n",
    "    - One Year - 1y\n",
    "    - Two Year - 2y\n",
    "    - rest all - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99dd0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaced column value\n",
    "def replace(column_val):\n",
    "    if column_val==\"Month-to-month\":\n",
    "        column_val=\"1m\"\n",
    "    elif column_val==\"One year\":\n",
    "        column_val=\"1y\"\n",
    "    elif column_val==\"Two year\":\n",
    "        column_val=\"2y\"\n",
    "    else:\n",
    "        column_val= \"Others\"\n",
    "    return column_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e21696f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract column values passed to the replace function and assigned new column value\n",
    "step2=step1.map(lambda x: (x[0],x[1],x[2],x[3],x[4],x[5],\n",
    "                           x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],replace(x[15]),x[16],x[17],x[18],x[19],x[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a46cb4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  '0',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  '1',\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  '29.85',\n",
       "  '29.85',\n",
       "  'No'),\n",
       " ('5575-GNVDE',\n",
       "  'Male',\n",
       "  '0',\n",
       "  'No',\n",
       "  'No',\n",
       "  '34',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'DSL',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1y',\n",
       "  'No',\n",
       "  'Mailed check',\n",
       "  '56.95',\n",
       "  '1889.5',\n",
       "  'No')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first two records \n",
    "step2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f3890359",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to convert numerical columns from string to int\n",
    "def string_to_int(val):\n",
    "    try:\n",
    "        return int(float(val))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ca6fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column 2,5,18,19 are numberical column so apply string_to_int function for converting string to int\n",
    "step3=step2.map(lambda x: (x[0],x[1],string_to_int(x[2]),x[3],x[4],string_to_int(x[5]),\n",
    "                           x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16],x[17],string_to_int(x[18]),string_to_int(x[19]),x[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5989c742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  0,\n",
       "  'Yes',\n",
       "  'No',\n",
       "  1,\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  29,\n",
       "  29,\n",
       "  'No')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first record\n",
    "step3.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b620b4f",
   "metadata": {},
   "source": [
    "## C. Describe the categorical and numerical columns seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add7b15",
   "metadata": {},
   "source": [
    "### i. Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6fd684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show only numerical columns in the given dataset\n",
    "num_data=step3.map(lambda x: (x[2],x[5],x[18],x[19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abcce48e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 29, 29), (0, 34, 56, 1889), (0, 2, 53, 108), (0, 45, 42, 1840)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first four records\n",
    "num_data.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c03e4",
   "metadata": {},
   "source": [
    "#### mean and variance of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "07e0ede3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ statistic analysis -----------\n",
      "mean : [1.62146812e-01 3.23711487e+01 6.42958966e+01 2.27926509e+03]\n",
      "variance : [1.35874516e-01 6.03168108e+02 9.05572188e+02 5.13834082e+06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#import necessary packages \n",
    "import numpy as np\n",
    "from pyspark.mllib.stat import Statistics\n",
    "num_data=step3.map(lambda x: (x[2],x[5],x[18],x[19])) # numberical cols \n",
    "num_data.take(5)\n",
    "summary = Statistics.colStats(num_data)\n",
    "print(\"------ statistic analysis -----------\")\n",
    "print(\"mean :\",summary.mean())  # a dense vector containing the mean value for each column\n",
    "print(\"variance :\",summary.variance())  # column-wise variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef050e",
   "metadata": {},
   "source": [
    "#### Maximum and minimum entry of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "28150c71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------statistic analysis----------------------\n",
      " Maximum  entry  in each column (1, 72, 117, 8436)\n",
      "Minimum  entery  in each column (0, 0, 19, 0)\n"
     ]
    }
   ],
   "source": [
    "#aggregate function for numerical columns\n",
    "print(\"------statistic analysis----------------------\")\n",
    "print(\" Maximum  entry  in each column\",num_data.max())\n",
    "print(\"Minimum  entery  in each column\",num_data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24d839",
   "metadata": {},
   "source": [
    "### ii. Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c340824f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  [7],\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  'No')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show categorical columns \n",
    "cat_data=step3.map(lambda x:(x[0],x[1],x[3],x[4],x[6],[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16],x[17],x[20]))\n",
    "#show first records of category data\n",
    "cat_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4fc22a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of records \n",
    "cat_data.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6367502",
   "metadata": {},
   "outputs": [],
   "source": [
    "##User defined functions \n",
    "# Module for changing string to int\n",
    "def string_to_int(val):\n",
    "    try:\n",
    "        return int(float(val))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Module getting the count\n",
    "def count(x):\n",
    "    temp=0\n",
    "    for val in list(x):\n",
    "        temp = temp + val[1]\n",
    "        out = str(val[0])+\",\"+str(temp)\n",
    "    return (out)\n",
    "\n",
    "#module for average\n",
    "def mean_val(x):\n",
    "    sums=0\n",
    "    l=0\n",
    "    for i in x:\n",
    "        sums= sums + i[1]\n",
    "        l=l+1\n",
    "        avg=round(sums/l,2)\n",
    "        \n",
    "    return (avg)\n",
    "\n",
    "## module for replace value\n",
    "def replace(column_val):\n",
    "    if column_val==\"Month-to-month\":\n",
    "        column_val=\"1m\"\n",
    "    elif column_val==\"One year\":\n",
    "        column_val=\"1y\"\n",
    "    elif column_val==\"Two year\":\n",
    "        column_val=\"2y\"\n",
    "    else:\n",
    "        column_val= \"Others\"\n",
    "    return column_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61075803",
   "metadata": {},
   "source": [
    "### count Churn\n",
    "- Counting number of customer  churn \"Yes\"  or not churn \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa84f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----count number of customer churn or not churn ------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['No,194387', 'Yes,33603']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding header, split data by ',', count number of customer churn \"Yes\" or not churn \"No\"\n",
    "col=[0,1,3,4,6,7,8,9,10,11,12,13,14,15,16,17,20]\n",
    "cat_count = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).\\\n",
    "            map(lambda x: (x[0],x[1],x[2],x[3],x[4],x[5],\n",
    "                           x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],replace(x[15]),x[16],x[17],x[18],x[19],x[20])).map(\n",
    "    lambda x: ((x[20]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "print(\"----count number of customer churn or not churn ------------\")\n",
    "cat_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "61afcce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Count number of famale and male-------- \n",
      "['Female,112469', 'Male,115521']\n"
     ]
    }
   ],
   "source": [
    "#Count number of gender \"Female\" and 'Male'\n",
    "cat_ge = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).\\\n",
    "           map(\n",
    "    lambda x: ((x[1]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "print(\"----------Count number of famale and male-------- \")\n",
    "print(cat_ge.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab50c1",
   "metadata": {},
   "source": [
    "### Distribution of different internet plans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "11227e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------shown different internet plans----------\n",
      "['DSL,79461', 'Fiber optic,101914', 'No,46615']\n"
     ]
    }
   ],
   "source": [
    "#Count number of mobile services such as DSL,Fiber and No\n",
    "cat_service = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[8]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "print(\"-------shown different internet plans----------\")\n",
    "print(cat_service.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c940fc0",
   "metadata": {},
   "source": [
    "###  Distribution of different PaymentMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd14dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----shown different Payment Method-----------\n",
      "['Electronic check,59538', 'Mailed check,35190', 'Bank transfer (automatic),67406', 'Credit card (automatic),65856']\n"
     ]
    }
   ],
   "source": [
    "#counting number of payment method such as electronic check, mailed check, bang transfer, and credit card\n",
    "cat_pyMethod = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[17]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "print(\"-----shown different Payment Method-----------\")\n",
    "print(cat_pyMethod.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721dfb1",
   "metadata": {},
   "source": [
    "### Distribution of different service Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ebff2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Different service Lines-------- \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['No phone service,21645', 'No,81817', 'Yes,124528']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting number of serivice lines such as \"no phone service\",'No','Yes'\n",
    "cat_pyMethod = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[7]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "print(\"----------Different service Lines-------- \")\n",
    "cat_pyMethod.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a924",
   "metadata": {},
   "source": [
    "### Number of  customer churn w.r.t gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6e6f922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Number of customer churn and not churn w.r.t gender----\n",
      "[\"('No', 'Female'),96502\", \"('No', 'Male'),97885\", \"('Yes', 'Male'),17636\", \"('Yes', 'Female'),15967\"]\n"
     ]
    }
   ],
   "source": [
    "# couting number of churn or not churn with respect to the gender\n",
    "cat_gender = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[20],x[1]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "\n",
    "print(\"---Number of customer churn and not churn w.r.t gender----\")\n",
    "print(cat_gender.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735ae42",
   "metadata": {},
   "source": [
    "## B. Unique customer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a81d7bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Customer\n",
      "show first three unique customer ['7590-VHVEG,1', '5575-GNVDE,34', '3668-QPYBK,2']\n",
      "----------------------------------------------------------------------\n",
      "Number of unique customer 7043\n"
     ]
    }
   ],
   "source": [
    "cat_customer = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[0]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "\n",
    "print(\"Unique Customer\")\n",
    "print(\"show first three unique customer\",cat_customer.take(3))\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Number of unique customer\",cat_customer.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e8ba5",
   "metadata": {},
   "source": [
    "## D.  GroupBy contract and avg of totalcharges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d3b6b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1m', 29), ('1y', 1889)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show contract and totalcharge column\n",
    "step4=step3.map(lambda x: (x[15],x[19]))\n",
    "step4.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7cb64a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Average totalcharges in each of 1m,1y and 2y--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1m', 1368.79), ('1y', 3032.14), ('2y', 3706.47)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #groupby contract and avg totalcharges   \n",
    "def mean_val(x):\n",
    "    sums=0\n",
    "    l=0\n",
    "    for i in x:\n",
    "        sums= sums + i[1]\n",
    "        l=l+1\n",
    "        avg=round(sums/l,2)\n",
    "        \n",
    "    return (avg)\n",
    "    \n",
    "step5= step4.map(lambda x:((x[0]),string_to_int(x[1])))\\\n",
    "            .map(lambda x: (x[0],x[1]))\\\n",
    "            .groupBy(lambda x: (x[0])).\\\n",
    "            map(lambda x: (x[0],mean_val(x[1]))).coalesce(1)\n",
    "\n",
    "print(\"---------Average totalcharges in each of 1m,1y and 2y--------------\")           \n",
    "step5.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fc4a8",
   "metadata": {},
   "source": [
    "#### As we can see above analysis,  average total charge in 1m is ->1368.79, 1y->3032.14 and 2y->3706.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7ae10",
   "metadata": {},
   "source": [
    "## E. Using accumulator add the totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cbd05dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Total Charges-------------------\n",
      "Total Charges occured:  16052864\n",
      "---------------------------------------\n",
      "Number of customer entries:  7043\n"
     ]
    }
   ],
   "source": [
    "#starting from 0 and add up all the totalcharges \n",
    "accuSum=spark.sparkContext.accumulator(0)\n",
    "def countFun(x):\n",
    "    global accuSum\n",
    "    accuSum+=x\n",
    "totalcharges.foreach(countFun)\n",
    "print(\"-----Total Charges-------------------\")\n",
    "print(\"Total Charges occured: \", accuSum.value)\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "accumCount=spark.sparkContext.accumulator(0)\n",
    "totalcharges.foreach(lambda x:accumCount.add(1))\n",
    "print(\"Number of customer entries: \", accumCount.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b048d1",
   "metadata": {},
   "source": [
    "# 3. Load: Save analysis report\n",
    "\n",
    "- GroupBy contract and avg of totalcharges save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c68e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save textfile in folder Report with file name avg_totalcharges\n",
    "step5.saveAsTextFile(\"Report/avg_totalCharges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcbd0f",
   "metadata": {},
   "source": [
    "--------------------------------------------------------END-------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
